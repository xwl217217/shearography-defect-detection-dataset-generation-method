batch_size: 24
iters: 24000
EvalReader:
  collate_batch: false
train_dataset:
  type: Dataset
  dataset_root: data/dataset
  train_path: data/dataset/train.txt
  num_classes: 2
  transforms:
    - type: ResizeStepScaling
      min_scale_factor: 0.5
      max_scale_factor: 2.0
      scale_step_size: 0.25
    - type: RandomPaddingCrop
      crop_size: [512, 512]
    - type: RandomHorizontalFlip
    - type: Normalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
  mode: train

val_dataset:
  type: Dataset
  dataset_root: data/dataset
  val_path: data/dataset/val.txt
  num_classes: 2
  mode: val
  transforms:
    - type: Resize
      target_size: [512, 512]
      keep_ratio: True
      size_divisor: 32
    - type: Normalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
  mode: val
export:
  transforms:
    - type: Resize
      target_size: [512, 512]
      keep_ratio: True
      size_divisor: 32
    - type: Normalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

optimizer:
  type: AdamW
  beta1: 0.9
  beta2: 0.999
  weight_decay: 0.01

lr_scheduler:
  type: PolynomialDecay
  learning_rate: 0.0001
  end_lr: 0
  power: 0.9

loss:
  types:
    - type: CrossEntropyLoss
  coef: [1]



model:
  type: SegFormer2
  backbone:
    type: MixVisionTransformer_B3
  embedding_dim: 256
  num_classes: 2
 
